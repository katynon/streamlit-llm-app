from dotenv import load_dotenv
load_dotenv()

# app.py
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# -----------------------------
# LLMå‘¼ã³å‡ºã—é–¢æ•°ï¼ˆèª²é¡Œè¦ä»¶ï¼‰
# -----------------------------
def run_llm(user_input: str, expert_type: str) -> str:
    """
    å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã¨å°‚é–€å®¶ã‚¿ã‚¤ãƒ—ã‚’å—ã‘å–ã‚Šã€
    LLMã®å›ç­”ã‚’æ–‡å­—åˆ—ã¨ã—ã¦è¿”ã™
    """

    # å°‚é–€å®¶ã”ã¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    if expert_type == "A":
        system_message = (
            "ã‚ãªãŸã¯çµŒé¨“è±Šå¯ŒãªPythonãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®å°‚é–€å®¶ã§ã™ã€‚"
            "åˆå¿ƒè€…ã«ã‚‚åˆ†ã‹ã‚Šã‚„ã™ãã€å…·ä½“ä¾‹ã‚’äº¤ãˆã¦èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
        )
    else:
        system_message = (
            "ã‚ãªãŸã¯å„ªç§€ãªãƒ“ã‚¸ãƒã‚¹ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
            "çµŒå–¶è¦–ç‚¹ãƒ»å®Ÿå‹™è¦–ç‚¹ã§ã€ç°¡æ½”ã‹ã¤è«–ç†çš„ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
        )

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_message),
        ("human", "{input}")
    ])

    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.3
    )

    chain = prompt | llm
    result = chain.invoke({"input": user_input})

    return result.content


# -----------------------------
# Streamlit UI
# -----------------------------
st.title("LLMæ­è¼‰ Webã‚¢ãƒ—ãƒªï¼ˆLangChain Ã— Pythonï¼‰")

st.markdown("""
### ã‚¢ãƒ—ãƒªæ¦‚è¦
ã“ã®ã‚¢ãƒ—ãƒªã¯ã€å…¥åŠ›ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚‚ã¨ã«  
**é¸æŠã—ãŸå°‚é–€å®¶ã®ç«‹å ´ã§LLMãŒå›ç­”ã‚’ç”Ÿæˆã™ã‚‹Webã‚¢ãƒ—ãƒª**ã§ã™ã€‚

### æ“ä½œæ–¹æ³•
1. å°‚é–€å®¶ã®ç¨®é¡ã‚’ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§é¸æŠã—ã¦ãã ã•ã„  
2. è³ªå•ã‚„ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„  
3. ã€Œé€ä¿¡ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨ã€LLMã®å›ç­”ãŒè¡¨ç¤ºã•ã‚Œã¾ã™
""")

expert = st.radio(
    "å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸æŠã—ã¦ãã ã•ã„",
    options=["A", "B"],
    format_func=lambda x: "Pythonã®å°‚é–€å®¶" if x == "A" else "ãƒ“ã‚¸ãƒã‚¹ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ"
)

user_input = st.text_area("è³ªå•ãƒ»ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

if st.button("é€ä¿¡"):
    if user_input.strip() == "":
        st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("LLMãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
            answer = run_llm(user_input, expert)
        st.subheader("ğŸ’¡ å›ç­”")
        st.write(answer)
